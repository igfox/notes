# Counterfactual Policy Evaluation
In counterfactual policy estimate (CPE), the goal is to evaluate the performance of a learned policy using only observational data generated according to a different policy (typically referred to as a behavior policy). The main challenge is to account for expected differences in state distributions under the learned policy relative to the behavior policy. This article provides an overview of different common methods for CPE, focusing on methods used in ReAgent.

## Overview
http://alekhagarwal.net/bandits_and_rl/off_policy.pdf: [[alekh_agarwal_off-policy_evaluation_and_learning]] alekh_agarwal_off-policy_evaluation_and_learning 

## Direct Method

## Inverse Propensity Score

## Doubly Robust Estimator

## Sequential Doubly Robust Estimator

## Weighted Double Robust Estimator

## MAGIC

## DualDICE
